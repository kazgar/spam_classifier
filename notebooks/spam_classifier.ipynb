{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "from src.spam_classifier.constants import PROJECT_ROOT\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        msg = BytesParser(policy=policy.default).parse(f)\n",
    "\n",
    "    try:\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                if part.get_content_type() == \"text/plain\" and not part.get_content_disposition():\n",
    "                    body += f\"{part.get_content()} \"\n",
    "                    break\n",
    "        else:\n",
    "            body = msg.get_content()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath.name}: {e}\")\n",
    "\n",
    "    return {\"body\": body, \"type\": msg.get_content_type()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = []\n",
    "spam_emails = []\n",
    "for dir in (DATA_DIR).iterdir():\n",
    "    if \"spam\" in dir.name:\n",
    "        spam_emails += [parse_email(f) for f in dir.iterdir()]\n",
    "    else:\n",
    "        ham_emails += [parse_email(f) for f in dir.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.spam_classifier.mail_class import Mail\n",
    "\n",
    "\n",
    "class MailTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        email_list = []\n",
    "        for email in tqdm(X):\n",
    "            body, type = email[\"body\"], email[\"type\"]\n",
    "            email_list.append(Mail(body, type).transform_mail())\n",
    "        return email_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MailVocabulary(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocab_size: int = 1000):\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        word_counter = {}\n",
    "        for word_dict in X:\n",
    "            for word, count in word_dict.items():\n",
    "                word_counter[word] = word_counter.get(word, 0) + count\n",
    "        most_common = list(\n",
    "            dict(sorted(word_counter.items(), key=lambda x: x[1], reverse=True)).keys()\n",
    "        )[: self.vocab_size]\n",
    "        self.vocabulary_ = {word: i for i, word in enumerate([\"unknown\"] + most_common)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for word_dict in X:\n",
    "            email_dict = [\n",
    "                word_dict[word] if word in word_dict else 0 for word in self.vocabulary_.keys()\n",
    "            ]\n",
    "            transformed_X.append(email_dict)\n",
    "\n",
    "        return transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ham_emails + spam_emails\n",
    "y = [0 if email in ham_emails else 1 for email in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=random_state\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, stratify=y_test, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"email_transformer\", MailTransformer()),\n",
    "        (\"mail_vocab\", MailVocabulary()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipeline = pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = [fitted_pipeline.transform(X) for X in [X_train, X_val, X_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_params = {\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"],\n",
    "    \"max_iter\": [1000],\n",
    "}\n",
    "\n",
    "lr_param_grid = GridSearchCV(\n",
    "    estimator=lr_clf, param_grid=lr_params, cv=10, scoring=\"accuracy\", verbose=2, n_jobs=-1\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_param_grid.best_score_)\n",
    "print(lr_param_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = lr_param_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(lr_clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
