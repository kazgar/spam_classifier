{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Vocabulary\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from src.spam_classifier.constants import PROJECT_ROOT\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        msg = BytesParser(policy=policy.default).parse(f)\n",
    "\n",
    "    try:\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                if part.get_content_type() == \"text/plain\" and not part.get_content_disposition():\n",
    "                    body += f\"{part.get_content()} \"\n",
    "                    break\n",
    "        else:\n",
    "            body = msg.get_content()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath.name}: {e}\")\n",
    "\n",
    "    return {\"body\": body, \"type\": msg.get_content_type()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in (DATA_DIR).iterdir():\n",
    "    if \"ham\" in dir.name:\n",
    "        print(len(list(dir.iterdir())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = []\n",
    "spam_emails = []\n",
    "for dir in (DATA_DIR).iterdir():\n",
    "    if \"spam\" in dir.name:\n",
    "        spam_emails += [parse_email(f) for f in dir.iterdir()]\n",
    "    else:\n",
    "        ham_emails += [parse_email(f) for f in dir.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from src.spam_classifier.mail_class import Mail\n",
    "\n",
    "\n",
    "class MailTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        email_list = []\n",
    "        for row in X.rows():\n",
    "            body, type = row\n",
    "            email_list.append(Mail(body, type).transform_mail())\n",
    "        return email_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MailVocabulary(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocab_size: int = 1000):\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        word_counter = {}\n",
    "        for word_dict in X:\n",
    "            for word, count in word_dict.items():\n",
    "                word_counter[word] = word_counter.get(word, 0) + count\n",
    "        most_common = list(\n",
    "            dict(sorted(word_counter.items(), key=lambda x: x[1], reverse=True)).keys()\n",
    "        )[: self.vocab_size]\n",
    "        self.vocabulary_ = {word: i for i, word in enumerate([\"unknown\"] + most_common)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for word_dict in X:\n",
    "            email_dict = [\n",
    "                word_dict[count] for _, count in zip(self.vocabulary_.keys(), word_dict.keys())\n",
    "            ]\n",
    "            transformed_X.append(email_dict)\n",
    "\n",
    "        return transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ham_emails + spam_emails\n",
    "y = [0 if email in ham_emails else 1 for email in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=random_state\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, stratify=y_test, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
